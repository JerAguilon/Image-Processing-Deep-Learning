{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cuda not enabled'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.plots import *\n",
    "from fastai.structured import *\n",
    "\n",
    "import json, pdb\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects\n",
    "if torch.cuda.is_available():\n",
    "    display(\"Cuda enabled\")\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    display(\"Cuda not enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Data Augmentation\n",
    "\n",
    "We're going to be using a subset fo the [Microsoft COCO](http://cocodataset.org/#download) to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/')\n",
    "RAW_IMAGES = PATH/'raw'\n",
    "TRAIN_IMAGES = PATH/'train/images'\n",
    "TRAIN_CSV = PATH/'train/rotation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://stackoverflow.com/questions/16702966/rotate-image-and-crop-out-black-borders\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    \"\"\"\n",
    "    Rotates an OpenCV 2 / NumPy image about it's centre by the given angle\n",
    "    (in degrees). The returned image will be large enough to hold the entire\n",
    "    new image, with a black background\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the image size\n",
    "    # No that's not an error - NumPy stores image matricies backwards\n",
    "    image_size = (image.shape[1], image.shape[0])\n",
    "    image_center = tuple(np.array(image_size) / 2)\n",
    "\n",
    "    # Convert the OpenCV 3x2 rotation matrix to 3x3\n",
    "    rot_mat = np.vstack(\n",
    "        [cv2.getRotationMatrix2D(image_center, angle, 1.0), [0, 0, 1]]\n",
    "    )\n",
    "\n",
    "    rot_mat_notranslate = np.matrix(rot_mat[0:2, 0:2])\n",
    "\n",
    "    # Shorthand for below calcs\n",
    "    image_w2 = image_size[0] * 0.5\n",
    "    image_h2 = image_size[1] * 0.5\n",
    "\n",
    "    # Obtain the rotated coordinates of the image corners\n",
    "    rotated_coords = [\n",
    "        (np.array([-image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n",
    "        (np.array([ image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n",
    "        (np.array([-image_w2, -image_h2]) * rot_mat_notranslate).A[0],\n",
    "        (np.array([ image_w2, -image_h2]) * rot_mat_notranslate).A[0]\n",
    "    ]\n",
    "\n",
    "    # Find the size of the new image\n",
    "    x_coords = [pt[0] for pt in rotated_coords]\n",
    "    x_pos = [x for x in x_coords if x > 0]\n",
    "    x_neg = [x for x in x_coords if x < 0]\n",
    "\n",
    "    y_coords = [pt[1] for pt in rotated_coords]\n",
    "    y_pos = [y for y in y_coords if y > 0]\n",
    "    y_neg = [y for y in y_coords if y < 0]\n",
    "\n",
    "    right_bound = max(x_pos)\n",
    "    left_bound = min(x_neg)\n",
    "    top_bound = max(y_pos)\n",
    "    bot_bound = min(y_neg)\n",
    "\n",
    "    new_w = int(abs(right_bound - left_bound))\n",
    "    new_h = int(abs(top_bound - bot_bound))\n",
    "\n",
    "    # We require a translation matrix to keep the image centred\n",
    "    trans_mat = np.matrix([\n",
    "        [1, 0, int(new_w * 0.5 - image_w2)],\n",
    "        [0, 1, int(new_h * 0.5 - image_h2)],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    # Compute the tranform for the combined rotation and translation\n",
    "    affine_mat = (np.matrix(trans_mat) * np.matrix(rot_mat))[0:2, :]\n",
    "\n",
    "    # Apply the transform\n",
    "    result = cv2.warpAffine(\n",
    "        image,\n",
    "        affine_mat,\n",
    "        (new_w, new_h),\n",
    "        flags=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def largest_rotated_rect(w, h, angle):\n",
    "    \"\"\"\n",
    "    Given a rectangle of size wxh that has been rotated by 'angle' (in\n",
    "    radians), computes the width and height of the largest possible\n",
    "    axis-aligned rectangle within the rotated rectangle.\n",
    "\n",
    "    Original JS code by 'Andri' and Magnus Hoff from Stack Overflow\n",
    "\n",
    "    Converted to Python by Aaron Snoswell\n",
    "    \"\"\"\n",
    "\n",
    "    quadrant = int(math.floor(angle / (math.pi / 2))) & 3\n",
    "    sign_alpha = angle if ((quadrant & 1) == 0) else math.pi - angle\n",
    "    alpha = (sign_alpha % math.pi + math.pi) % math.pi\n",
    "\n",
    "    bb_w = w * math.cos(alpha) + h * math.sin(alpha)\n",
    "    bb_h = w * math.sin(alpha) + h * math.cos(alpha)\n",
    "\n",
    "    gamma = math.atan2(bb_w, bb_w) if (w < h) else math.atan2(bb_w, bb_w)\n",
    "\n",
    "    delta = math.pi - alpha - gamma\n",
    "\n",
    "    length = h if (w < h) else w\n",
    "\n",
    "    d = length * math.cos(alpha)\n",
    "    a = d * math.sin(alpha) / math.sin(delta)\n",
    "\n",
    "    y = a * math.cos(gamma)\n",
    "    x = y * math.tan(gamma)\n",
    "\n",
    "    return (\n",
    "        bb_w - 2 * x,\n",
    "        bb_h - 2 * y\n",
    "    )\n",
    "\n",
    "\n",
    "def crop_around_center(image, width, height):\n",
    "    \"\"\"\n",
    "    Given a NumPy / OpenCV 2 image, crops it to the given width and height,\n",
    "    around it's centre point\n",
    "    \"\"\"\n",
    "\n",
    "    image_size = (image.shape[1], image.shape[0])\n",
    "    image_center = (int(image_size[0] * 0.5), int(image_size[1] * 0.5))\n",
    "\n",
    "    if(width > image_size[0]):\n",
    "        width = image_size[0]\n",
    "\n",
    "    if(height > image_size[1]):\n",
    "        height = image_size[1]\n",
    "\n",
    "    x1 = int(image_center[0] - width * 0.5)\n",
    "    x2 = int(image_center[0] + width * 0.5)\n",
    "    y1 = int(image_center[1] - height * 0.5)\n",
    "    y2 = int(image_center[1] + height * 0.5)\n",
    "\n",
    "    return image[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rand_file_name():\n",
    "    return ''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(15)) + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_files = glob(str(TRAIN_IMAGES) + '/*')\n",
    "for f in train_files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_files = os.listdir(RAW_IMAGES)\n",
    "\n",
    "MAX_ROTATION_ABS = 45 # rotate no more than 45 degrees\n",
    "NUM_AUGMENTATIONS = 1\n",
    "IMAGE_SIZE = 224 # 256\n",
    "name_to_rotation = {}\n",
    "\n",
    "total = 0\n",
    "\n",
    "print(f'Processing {len(img_files)} images.')\n",
    "for img_file in img_files:\n",
    "    if total % 200 == 0:\n",
    "        print(f'{total} processed.')\n",
    "    for i in range(NUM_AUGMENTATIONS):\n",
    "        rotation_deg = (random.random() * MAX_ROTATION_ABS * 2) - MAX_ROTATION_ABS\n",
    "\n",
    "        img = plt.imread(RAW_IMAGES/img_file)\n",
    "        img = Image.fromarray(img)\n",
    "        img = img.resize((IMAGE_SIZE*2, IMAGE_SIZE*2))\n",
    "        img = np.array(img)\n",
    "        \n",
    "        image_height, image_width = img.shape[0:2]\n",
    "\n",
    "        new_image = rotate_image(img, rotation_deg)\n",
    "        new_image = crop_around_center(\n",
    "            new_image,\n",
    "            *largest_rotated_rect(\n",
    "                image_width,\n",
    "                image_height,\n",
    "                math.radians(rotation_deg)\n",
    "            )\n",
    "        )\n",
    "        if len(new_image.shape) != 3 or new_image.shape[2] != 3:\n",
    "            continue # TODO: Allow for black and white examples\n",
    "        file_name = gen_rand_file_name()\n",
    "        save_image = Image.fromarray(new_image)\n",
    "        save_image = save_image.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "        save_image.save(TRAIN_IMAGES/file_name)\n",
    "        name_to_rotation[file_name] = -rotation_deg\n",
    "    total += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame.from_dict(\n",
    "    name_to_rotation,\n",
    "    orient='index',\n",
    ")\n",
    "dataframe = dataframe.reset_index()\n",
    "dataframe.columns = ['filename', 'rotation']\n",
    "dataframe = dataframe.set_index('filename')\n",
    "dataframe.to_csv(TRAIN_CSV)\n",
    "dataframe = dataframe.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = plt.imread(TRAIN_IMAGES/dataframe.filename[100])\n",
    "display(plt.imshow(test_image))\n",
    "display(dataframe.rotation[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rotate_image(test_image, dataframe.rotation[100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>rotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cmr2sv7vy2ma3zp.jpg</td>\n",
       "      <td>4.368465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dtx35czwbqk3mdi.jpg</td>\n",
       "      <td>1.962879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ntvz7tku03og5jx.jpg</td>\n",
       "      <td>11.231288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hkha26nuugb9icd.jpg</td>\n",
       "      <td>-14.468306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wumlytrhbx7nk2g.jpg</td>\n",
       "      <td>26.567956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename   rotation\n",
       "0  cmr2sv7vy2ma3zp.jpg   4.368465\n",
       "1  dtx35czwbqk3mdi.jpg   1.962879\n",
       "2  ntvz7tku03og5jx.jpg  11.231288\n",
       "3  hkha26nuugb9icd.jpg -14.468306\n",
       "4  wumlytrhbx7nk2g.jpg  26.567956"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(TRAIN_CSV)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mask = np.random.rand(len(dataframe)) < .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataframe[training_mask].reset_index()\n",
    "validation = dataframe[~training_mask].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotationDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.file_names = dataframe.filename\n",
    "        self.rotations = dataframe.rotation\n",
    "        \n",
    "    def __len__(self): return len(self.file_names)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        file_name, y = self.file_names[i], self.rotations[i]\n",
    "        image_data = plt.imread(TRAIN_IMAGES/file_name).astype('int16')\n",
    "        image_data = np.moveaxis(image_data, 2, 0)\n",
    "        return (\n",
    "            image_data,\n",
    "            y\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RotationDataset(dataframe)\n",
    "val_dataset = RotationDataset(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 64,\n",
    "    num_workers=4\n",
    ")\n",
    "validation_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StdConv(nn.Module):\n",
    "    def __init__(self, nin, nout, stride=2, drop=.1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(nin, nout, 3, stride=stride, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(nout)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.drop(self.bn(F.relu(self.conv(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Input - 3@256x256\n",
    "        self.conv1 = StdConv(3, 16)\n",
    "        # 16@128x128\n",
    "        self.conv2 = StdConv(16, 32)\n",
    "        # 32@64x64\n",
    "        self.conv3 = StdConv(32, 64)\n",
    "        # 64@32x32\n",
    "        self.conv4 = StdConv(64, 128)\n",
    "        # 128@16x16\n",
    "        self.fc1 = nn.Linear(128*16*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 1)#60)\n",
    "        #self.fc3 = nn.Linear(60, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RotationNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/jeremy/.torch/models/resnet18-5c106cde.pth\n",
      " 33%|███▎      | 15671296/46827520 [00:09<00:22, 1357415.67it/s]/home/jeremy/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "100%|██████████| 46827520/46827520 [00:27<00:00, 1723277.57it/s]\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = torch.nn.Linear(num_ftrs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Variable(X.float())\n",
    "y = Variable(y.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 224, 224])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=.001)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "EPOCHS = 8\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    resnet.train(True)\n",
    "    running_loss_train = 0\n",
    "    total = 0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "        X, y = batch\n",
    "        X = Variable(X.float())\n",
    "        y = Variable(y.float())\n",
    "        prediction = resnet(X)     # input x and predict based on x\n",
    "        loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "        running_loss_train += loss.data[0]\n",
    "        total += 1\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        optimizer.step()        # apply gradients\n",
    "    train_loss = running_loss_train / total\n",
    "    print(f\"Training Loss: {train_loss}\")\n",
    "    \n",
    "    resnet.train(False)\n",
    "    running_loss_val = 0\n",
    "    total = 0\n",
    "    for i, batch in enumerate(validation_loader):\n",
    "        X, y = batch\n",
    "        X = Variable(X.float())\n",
    "        y = Variable(y.float())\n",
    "        prediction = resnet(X)     # input x and predict based on x\n",
    "        val_loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "        running_loss_val += val_loss.data[0]\n",
    "        total += 1\n",
    "        \n",
    "    validation_loss = running_loss_val / total\n",
    "    print(f\"Validation Loss: {validation_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
